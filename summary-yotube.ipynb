{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pavansannadi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numba\\__init__.py:48: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.22.0)\n",
      "  import scipy\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.retrievers import AzureCognitiveSearchRetriever\n",
    "from langchain_community.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from operator import itemgetter\n",
    "import tempfile\n",
    "import whisper\n",
    "from pytube import YouTube\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "llm = AzureChatOpenAI(azure_deployment=\"gpt-4o\", api_version=\"2024-05-01-preview\",\n",
    "    temperature=0)\n",
    "\n",
    "def download_transcript():\n",
    "    tmpdir = \"C:/Tmp/\"\n",
    "    if not os.path.exists(\"transcription.txt\"):\n",
    "        youtube = YouTube(\"https://www.youtube.com/watch?v=GSsIv0GQTUo\")\n",
    "        audio = youtube.streams.filter(only_audio=True).first()\n",
    "\n",
    "        audio_test_file = audio.download(output_path=tmpdir)\n",
    "\n",
    "        client = AzureOpenAI(\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "            api_version=\"2024-02-01\",\n",
    "            azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        )\n",
    "\n",
    "        deployment_id = \"whisper\" #This will correspond to the custom name you chose for your deployment when you deployed a model.\"\n",
    "        \n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            file=open(audio_test_file, \"rb\"),            \n",
    "            model=deployment_id\n",
    "        )\n",
    "        # print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_transcript()\n",
    "\n",
    "with open(\"C:/Tmp/transcription.txt\", \"w\") as file:\n",
    "    file.write(transcription.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are an AI assistant that helps people find information.\n",
    "Please respond with the summarization of the video transcript provided as input.\n",
    "If you can't answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"C:/Tmp/transcription.txt\")\n",
    "text_documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings()\n",
    "vectorstore2 = DocArrayInMemorySearch.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The video transcript explains the concept of the String Constant Pool (SCP) in Java. The SCP, also known as the string pool, is a special region within the heap memory dedicated to storing string literals. When a string literal is created, Java checks if it already exists in the SCP. If it does, the existing string is reused; otherwise, a new string is added to the pool. The transcript provides examples to illustrate this behavior, showing that string literals with the same value point to the same memory location in the SCP, resulting in reference equality. Conversely, strings created with the `new` keyword are stored in different memory locations, leading to reference inequality. The video encourages viewers to subscribe and stay tuned for further videos on related topics.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": vectorstore2.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "chain.invoke(\"summarize the context?\").content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
